{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intro to Artificial Intelligence\n",
    "\n",
    "[link](https://classroom.udacity.com/courses/cs271)\n",
    "\n",
    "#### Intelligent Agents\n",
    "\n",
    "An AI program is called an Intelligent Agent\n",
    "\n",
    "![](./data/img/diag1.png)\n",
    "\n",
    "There is an IA and there is an environment. The agent gets to interact with the env\n",
    "\n",
    "It can perceive the state of the env thru sensors\n",
    "\n",
    "It can affect its state thru its actuators\n",
    "\n",
    "But there needs to be a function that maps sensors to actuators. This is the key\n",
    "\n",
    "**How does an agent make decisions that it can carry out with its actuautors based on past sensor data**\n",
    "\n",
    "Those decisions take place many, many times in a loop : environment feedback -> sensor -> agent decision -> actuators interation with env and so on.. This is called **Perception Action Cycle**\n",
    "\n",
    "\n",
    "#### Basic Terminologies in AI\n",
    "\n",
    "1. Fully vs Partially observable\n",
    "\n",
    "An env is called fully observable if what the agent can sense at any pt of time is **completely sufficient** to make the optimal decision\n",
    "\n",
    "For eg, in a card game when all the cards are on the table, the sight of all the cards is sufficient\n",
    "\n",
    "But in poker u need memory of previous card moves\n",
    "\n",
    "![](./data/img/diag2.png)\n",
    "\n",
    "For many envs it is convenient to assume that the env has some internal state. For eg, in the card game where the state may be \"cards in the hand\". An env is **fully observable** if the sensors can always see the entire state of the env\n",
    "\n",
    "It is partially obs if the sensors can only see a fraction of the state yet measuring past info give us addntl info of the state that is not readily observable right now. So any game where past moves might be an indication of cards in a person's hand.. those games are PO and require differ treatment. Here agents would require internal memory\n",
    "\n",
    "2. Deterministic vs Stochastic\n",
    "\n",
    "Deterministic env is one where the agent's actions uniquely determine the outcome. \n",
    "In chess, the effect of moving a piece is completely predetermined\n",
    "\n",
    "Stochastic: Outcome of an action involves throwing of a dice, there is a certain randomness involved.\n",
    "Poker is also Stochastic because u are dealt cards, which is random\n",
    "\n",
    "3. Discrete vs Cont\n",
    "\n",
    "Discrete : finite action choices and finite many things u can sense. In chess, finite board positions and finite no of things u can do\n",
    "\n",
    "Cont: space of possible actions or things u can sense may be infiinite\n",
    "Throwing darts: infinite angles\n",
    "\n",
    "4. Benign vs Adversarial env\n",
    "\n",
    "Benign: env might be stochastic but it has no objective on its own that would contradict ur own obj\n",
    "Whether is benign.. \n",
    "Adversarial : chess..opponent is trying to beat u\n",
    "\n",
    "#### Quiz:\n",
    "\n",
    "![](./data/img/diag3.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
